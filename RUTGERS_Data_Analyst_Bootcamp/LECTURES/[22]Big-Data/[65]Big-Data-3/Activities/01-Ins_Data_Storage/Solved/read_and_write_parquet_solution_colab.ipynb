{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s2U0y6_MtZ9I",
    "outputId": "19aa9800-365c-456d-87cf-243d0bb9f41b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [Working]\r",
      "            \r",
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
      "\r",
      "0% [Waiting for headers] [Waiting for headers] [1 InRelease 0 B/3,622 B 0%] [Wa\r",
      "0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r",
      "                                                                               \r",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "\r",
      "                                                                               \r",
      "0% [Waiting for headers] [Waiting for headers] [Waiting for headers]\r",
      "                                                                    \r",
      "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
      "\r",
      "0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r",
      "                                                                               \r",
      "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
      "\r",
      "0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [4 InRelea\r",
      "                                                                               \r",
      "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
      "Get:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
      "Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,381 kB]\n",
      "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,127 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,290 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2,920 kB]\n",
      "Get:18 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [988 kB]\n",
      "Get:19 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,442 kB]\n",
      "Get:20 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\n",
      "Fetched 11.6 MB in 9s (1,335 kB/s)\n",
      "Reading package lists... Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Find the latest version of spark 3.x  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
    "# For example:\n",
    "# spark_version = 'spark-3.4.0'\n",
    "spark_version = 'spark-3.4.0'\n",
    "os.environ['SPARK_VERSION']=spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KLz5M7sFpO0W"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pyspark.sql import SparkSession\n",
    "# Import the time module so we can time our queries.\n",
    "import time\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"SparkSQL\").config(\"spark.driver.memory\", \"2g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CahJMb3cpWdW",
    "outputId": "13dc4e5d-9dc2-4acc-9bae-ab66cdd2dddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+-------+-----+-----+----------+-------------------+----------------+------------+--------------------+----------------+--------------------+-------------+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "|ISN_DOB_BIS_VIOL|BORO|    BIN|BLOCK|  LOT|ISSUE_DATE|VIOLATION_TYPE_CODE|VIOLATION_NUMBER|HOUSE_NUMBER|              STREET|DISPOSITION_DATE|DISPOSITION_COMMENTS|DEVICE_NUMBER|         DESCRIPTION|ECB_NUMBER|              NUMBER|  VIOLATION_CATEGORY|      VIOLATION_TYPE|\n",
      "+----------------+----+-------+-----+-----+----------+-------------------+----------------+------------+--------------------+----------------+--------------------+-------------+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "|         2286033|   1|1009713|00577|00019|  20180507|                  E|     9027/627971|          34|        WEST 14TH ST|        20220509|PPN203 AOC SUB 05...|      1P13420|                null|      null|V*050718E9027/627971|V*-DOB VIOLATION ...|E-ELEVATOR       ...|\n",
      "|         2533639|   1|1082666|00333|00001|  20210629|                  E|     9027/705433|          77|     COLUMBIA STREET|        20220509|PPN203 AOC SUB 05...|      1P27474|                null|      null|V*062921E9027/705433|V*-DOB VIOLATION ...|E-ELEVATOR       ...|\n",
      "|         2347979|   1|1083846|01130|00001|  20190423|                  E|     9028/648125|         200|   CENTRAL PARK WEST|        20220509|PPN203 AOC SUBMIT...|      1P40861|                null|      null|V*042319E9028/648125|V*-DOB VIOLATION ...|E-ELEVATOR       ...|\n",
      "|         2566336|   1|1057155|01889|07502|  20211123|                  E|     9028/710097|         845|        WEST END AVE|        20220509|PPN203 AOC SUB 05...|      1P14972|                null|      null|V*112321E9028/710097|V*-DOB VIOLATION ...|E-ELEVATOR       ...|\n",
      "|         2487351|   1|1041456|01387|00021|  20200925|                  E|     9028/689200|          31|             E 72 ST|        20220509|PPN203 AOC SUB 05...|      1P10910|                null|      null|V*092520E9028/689200|V*-DOB VIOLATION ...|E-ELEVATOR       ...|\n",
      "|         2579117|   3|3212907|07717|00054|  20220427|            AEUHAZ1|           00322|        3420|        QUENTIN ROAD|        20220509|000810 PAID INVOI...|         null|FAILURE TO CERTIF...| 39055131L|V*042722AEUHAZ100322|V*-DOB VIOLATION ...|AEUHAZ1-FAIL TO C...|\n",
      "|         2224356|   4|4445407|16155|00021|  20171206|                  E|     9027/617490|         320|    BEACH 100 STREET|        20220509|PPN203 AOC SUBMIT...|       4P4846|                null|      null|V*120617E9027/617490|V*-DOB VIOLATION ...|E-ELEVATOR       ...|\n",
      "|         1501541|   1|1010847|00611|00053|  20100706|             LANDMK|         11-0004|          10|      CHARLES STREET|        20220509|                null|         null|                null|      null|V*070610LANDMK11-...|V*-DOB VIOLATION ...|LANDMK-LANDMARK  ...|\n",
      "|         2435215|   1|1012256|00662|00011|  20200115|                  E|     9028/667509|     PIER 59|         NORTH RIVER|        20220509|PPN203 AOC SUB 05...|      1W10006|                null|      null|V*011520E9028/667509|V*-DOB VIOLATION ...|E-ELEVATOR       ...|\n",
      "|         2504960|   3|3379016|01220|00019|  20210123|                  E|     9028/696197|         715|         ST MARKS AV|        20220509|PPN203 AOC SUB 05...|       3P3165|                null|      null|V*012321E9028/696197|V*-DOB VIOLATION ...|E-ELEVATOR       ...|\n",
      "|         2579114|   3|3212907|07717|00054|  20220427|            AEUHAZ1|           00319|        3420|        QUENTIN ROAD|        20220509|000810 PAID INVOI...|         null|FAILURE TO CERTIF...| 39055126R|V*042722AEUHAZ100319|V*-DOB VIOLATION ...|AEUHAZ1-FAIL TO C...|\n",
      "|         2347971|   1|1083846|01130|00001|  20190424|                  E|     9028/650040|         200|   CENTRAL PARK WEST|        20220509|PPN203 AOC SUBMIT...|      1P29222|                null|      null|V*042419E9028/650040|V*-DOB VIOLATION ...|E-ELEVATOR       ...|\n",
      "|         2347976|   1|1083846|01130|00001|  20190423|                  E|     9028/650049|         200|   CENTRAL PARK WEST|        20220509|PPN203 AOC SUBMIT...|      1P40856|                null|      null|V*042319E9028/650049|V*-DOB VIOLATION ...|E-ELEVATOR       ...|\n",
      "|         2310631|   3|3079907|03439|00020|  20180809|            AEUHAZ1|           00316|         76A|       COOPER STREET|        20220509|            90252351|         null|FAILURE TO CERTIF...| 35331209P|V*080918AEUHAZ100316|V*-DOB VIOLATION ...|AEUHAZ1-FAIL TO C...|\n",
      "|         2582207|   4|4227230|10640|00029|  20220430|                  C|          ER02MA|       91-17|          215 STREET|            null|                null|         null|STRUCTURE RENDERE...|      null|      V043022CER02MA|V-DOB VIOLATION -...|C-CONSTRUCTION   ...|\n",
      "|         2539906|   1|1038758|01337|07502|  20210723|                  E|     9028/704512|           1|UNITED NATIONS PLAZA|        20220509|PPN203 AOC SUBMIT...|      1P37657|                null|      null|V*072321E9028/704512|V*-DOB VIOLATION ...|E-ELEVATOR       ...|\n",
      "|         2428141|   3|3425712|06766|07503|  20191102|              BENCH|           01025|        2068|        OCEAN AVENUE|        20220509|  CHALLENGE APPROVED|         null|FAILURE TO FILE B...|      null|  V*110219BENCH01025|V*-DOB VIOLATION ...|BENCH-FAILURE TO ...|\n",
      "|         2543985|   3|3116537|05080|00036|  20210824|                  E|     9028/706976|          21|         ST PAULS CT|        20220509|PPN203 AOC SUB 05...|       3P2286|                null|      null|V*082421E9028/706976|V*-DOB VIOLATION ...|E-ELEVATOR       ...|\n",
      "|         1705186|   1|1010847|00611|00053|  20120926|             LANDMK|         13-0202|          10|      CHARLES STREET|        20220509|                null|         null|                null|      null|V*092612LANDMK13-...|V*-DOB VIOLATION ...|LANDMK-LANDMARK  ...|\n",
      "|         2533638|   1|1082666|00333|00001|  20210629|                  E|     9027/705432|          77|     COLUMBIA STREET|        20220509|PPN203 AOC SUB 05...|      1P27473|                null|      null|V*062921E9027/705432|V*-DOB VIOLATION ...|E-ELEVATOR       ...|\n",
      "+----------------+----+-------+-----+-----+----------+-------------------+----------------+------------+--------------------+----------------+--------------------+-------------+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in data from S3 Bucket\n",
    "from pyspark import SparkFiles\n",
    "url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/3/NYC_Building_Violations.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "df = spark.read.csv(SparkFiles.get(\"NYC_Building_Violations.csv\"), sep=\",\", header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7fsnqRDqG2C",
    "outputId": "0f7a13b2-bb44-4366-ec37-dfd65e88c6c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|      VIOLATION_TYPE|sum(BORO)|\n",
      "+--------------------+---------+\n",
      "|LL10/80-LOCAL LAW...|   3609.0|\n",
      "|LL11/98-LOCAL LAW...|   9285.0|\n",
      "|HVIOS-NYCHA ELEV ...|    969.0|\n",
      "|P-PLUMBING       ...|  29480.0|\n",
      "|ACH1-(NYCHA) - EL...|   4949.0|\n",
      "|LANDMRK-LANDMARK ...|   5599.0|\n",
      "|LL5-LOCAL LAW 5/7...|   1363.0|\n",
      "|IMD-IMMEDIATE EME...|     13.0|\n",
      "|B-BOILER         ...|  17042.0|\n",
      "|FISP-FACADE SAFET...|   6889.0|\n",
      "|EGNCY-EMERGENCY  ...|  12607.0|\n",
      "|ES-ELECTRIC SIGNS...|  18378.0|\n",
      "|                null|    148.0|\n",
      "|L1198-LOCAL LAW 1...|  10656.0|\n",
      "|HBLVIO-HIGH PRESS...|  14628.0|\n",
      "|BENCH-FAILURE TO ...| 110285.0|\n",
      "|RWNRF-RETAINING W...|   4007.0|\n",
      "|FISPNRF-NO REPORT...|  21017.0|\n",
      "|LL2604-PHOTOLUMIN...|    679.0|\n",
      "|LL2604S-SPRINKLER...|   1513.0|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "--- 10.107470750808716 seconds ---\n"
     ]
    }
   ],
   "source": [
    " # Let's create a view with our DataFrame and run SQL that will sum up the boroughs by the type of violation.\n",
    "# We can output the time this step runs in seconds.\n",
    "# Because we are timing the executions, remember to run twice to eliminate the \"load time\" from the discussion.\n",
    "\n",
    "df.createOrReplaceTempView('violations')\n",
    "start_time = time.time()\n",
    "\n",
    "spark.sql(\"\"\"select VIOLATION_TYPE, sum(BORO) from violations group by 1\"\"\").show()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "g04Evw2jqHoK"
   },
   "outputs": [],
   "source": [
    "# Write out the data in parquet format\n",
    "# Note: That this is pretty much the same as writing out to a csv to your local directory.\n",
    "# We are telling Spark to overwrite all of the data if it already exists\n",
    "df.write.parquet('parquet_violations', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYiTD19bHuV4"
   },
   "source": [
    "\n",
    "\n",
    "*   click the folder icon on the left of the notebook to expose the folders and files stored in your colab enviornment.  Notice that a new folder is present with the same name as your parquet file (parquet_title_basic)\n",
    "*   inside of it you will find 'part-*.parquet' files and a '_SUCCESS' file. \n",
    "*  The '_SUCCESS' file is created when Spark creates a Parquet folder\n",
    "*  the part-* files are binary files that store your compressed data in columnar format\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2SaDjaQXqnPI"
   },
   "outputs": [],
   "source": [
    "# Read in our new parquet formatted data\n",
    "p_df=spark.read.parquet('parquet_violations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sT7d4hu-q32d"
   },
   "outputs": [],
   "source": [
    "# A parquet formatted DataFrame has all the same methods as a row-based DataFrame\n",
    "# We can convert the DataFrame to a view.\n",
    "p_df.createOrReplaceTempView('p_violations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwpUfAoeq71b",
    "outputId": "0d3653e6-176a-48a8-8359-a3309758d33e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|      VIOLATION_TYPE|sum(BORO)|\n",
      "+--------------------+---------+\n",
      "|LL10/80-LOCAL LAW...|   3609.0|\n",
      "|LL11/98-LOCAL LAW...|   9285.0|\n",
      "|HVIOS-NYCHA ELEV ...|    969.0|\n",
      "|P-PLUMBING       ...|  29480.0|\n",
      "|ACH1-(NYCHA) - EL...|   4949.0|\n",
      "|LANDMRK-LANDMARK ...|   5599.0|\n",
      "|LL5-LOCAL LAW 5/7...|   1363.0|\n",
      "|IMD-IMMEDIATE EME...|     13.0|\n",
      "|FISP-FACADE SAFET...|   6889.0|\n",
      "|B-BOILER         ...|  17042.0|\n",
      "|EGNCY-EMERGENCY  ...|  12607.0|\n",
      "|ES-ELECTRIC SIGNS...|  18378.0|\n",
      "|                null|    148.0|\n",
      "|L1198-LOCAL LAW 1...|  10656.0|\n",
      "|HBLVIO-HIGH PRESS...|  14628.0|\n",
      "|BENCH-FAILURE TO ...| 110285.0|\n",
      "|RWNRF-RETAINING W...|   4007.0|\n",
      "|FISPNRF-NO REPORT...|  21017.0|\n",
      "|LL2604-PHOTOLUMIN...|    679.0|\n",
      "|LL2604S-SPRINKLER...|   1513.0|\n",
      "+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "--- 4.009922027587891 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Run the same sql as above.  (Note: If you have small datasets it IS possible that times may be very close.)\n",
    "# Because we are timing the executions, remember to run twice to eliminate the \"load time\" from the discussion.\n",
    "\n",
    "start_time = time.time()\n",
    "spark.sql(\"\"\"select VIOLATION_TYPE, sum(BORO) from p_violations group by 1\"\"\").show()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yZY1lKBHrjLg"
   },
   "outputs": [],
   "source": [
    "# Writing out a csv file from Spark will also create a folder with \"part\" files.\n",
    "# These files are not binary or compressed and in reality are just normal csv files broken into partitions.\n",
    "# You can see the folder 'out_violations.csv' in your local directory.\n",
    "df.write.csv('out_violations.csv', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zit0gXHn4Hf2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
